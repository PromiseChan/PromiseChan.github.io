<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.23.2","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12,"onmobile":false},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":"mac","show_result":false},"fold":{"enable":false,"height":500},"language":false,"highlight_theme":"normal"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="FedChaingithub 仓库 : &amp;#103;&amp;#x69;&amp;#116;&amp;#64;&amp;#103;&amp;#105;&amp;#x74;&amp;#104;&amp;#117;&amp;#x62;&amp;#x2e;&amp;#99;&amp;#x6f;&amp;#109;:PromiseChan&#x2F;my_fed_chain.git">
<meta property="og:type" content="article">
<meta property="og:title" content="my_fedchain">
<meta property="og:url" content="http://example.com/2023/01/13/my-fedchain/index.html">
<meta property="og:site_name" content="PromiseChanの博客">
<meta property="og:description" content="FedChaingithub 仓库 : &amp;#103;&amp;#x69;&amp;#116;&amp;#64;&amp;#103;&amp;#105;&amp;#x74;&amp;#104;&amp;#117;&amp;#x62;&amp;#x2e;&amp;#99;&amp;#x6f;&amp;#109;:PromiseChan&#x2F;my_fed_chain.git">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-01-12T16:10:39.000Z">
<meta property="article:modified_time" content="2025-07-15T16:25:30.618Z">
<meta property="article:author" content="Promise Chan">
<meta property="article:tag" content="java, python, machine-learning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2023/01/13/my-fedchain/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2023/01/13/my-fedchain/","path":"2023/01/13/my-fedchain/","title":"my_fedchain"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>my_fedchain | PromiseChanの博客</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","mhchem":false,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">PromiseChanの博客</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>


      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#FedChain"><span class="nav-number">1.</span> <span class="nav-text">FedChain</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#fedSGD-iid"><span class="nav-number">1.1.</span> <span class="nav-text">fedSGD_iid</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fedSGD-niid"><span class="nav-number">1.2.</span> <span class="nav-text">fedSGD_niid</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fedavg-iid"><span class="nav-number">1.3.</span> <span class="nav-text">fedavg_iid</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fedavg-niid"><span class="nav-number">1.4.</span> <span class="nav-text">fedavg_niid</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MyArgs-%E5%8F%82%E6%95%B0"><span class="nav-number">1.5.</span> <span class="nav-text">MyArgs 参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifar-CNN-Model"><span class="nav-number">1.6.</span> <span class="nav-text">cifar CNN Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dataUtils"><span class="nav-number">1.7.</span> <span class="nav-text">dataUtils</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#fedChain"><span class="nav-number">1.8.</span> <span class="nav-text">fedChain</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FedRecon"><span class="nav-number">1.9.</span> <span class="nav-text">FedRecon</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

      <iframe frameborder="no" border="0" marginwidth="0"
         marginheight="0" width=330 
          height=86
          src="//music.163.com/outchain/player?type=2&id=27515324&auto=1&height=66">
      </iframe>

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Promise Chan"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">Promise Chan</p>
  <div class="site-description" itemprop="description">Coding & upgrading</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">44</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">67</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/promiseChan" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;promiseChan" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/01/13/my-fedchain/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="Promise Chan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PromiseChanの博客">
      <meta itemprop="description" content="Coding & upgrading">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="my_fedchain | PromiseChanの博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          my_fedchain
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-01-13 00:10:39" itemprop="dateCreated datePublished" datetime="2023-01-13T00:10:39+08:00">2023-01-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-16 00:25:30" itemprop="dateModified" datetime="2025-07-16T00:25:30+08:00">2025-07-16</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="FedChain"><a href="#FedChain" class="headerlink" title="FedChain"></a>FedChain</h1><p>github 仓库 : <a href="mailto:&#103;&#x69;&#116;&#64;&#103;&#105;&#x74;&#104;&#117;&#x62;&#x2e;&#99;&#x6f;&#109;">&#103;&#x69;&#116;&#64;&#103;&#105;&#x74;&#104;&#117;&#x62;&#x2e;&#99;&#x6f;&#109;</a>:PromiseChan&#x2F;my_fed_chain.git</p>
<span id="more"></span>

<p>进度：</p>
<p>fedchain VS fedAVG</p>
<p><strong>数据集:  cifar10</strong></p>
<table>
<thead>
<tr>
<th>数据分布</th>
<th>算法</th>
<th>精度</th>
</tr>
</thead>
<tbody><tr>
<td>iid</td>
<td>fedchain</td>
<td>68.52%</td>
</tr>
<tr>
<td>iid</td>
<td>fedavg</td>
<td>67.55%</td>
</tr>
<tr>
<td>iid</td>
<td>fedrecon</td>
<td>54.20%</td>
</tr>
<tr>
<td>iid</td>
<td>fedchain+fedrecon</td>
<td>47.10%</td>
</tr>
<tr>
<td>iin</td>
<td>fedchain+fedrecon(改)</td>
<td>47.50%</td>
</tr>
<tr>
<td>niid</td>
<td>fedchain</td>
<td>44.12%</td>
</tr>
<tr>
<td>niid</td>
<td>fedavg</td>
<td>57.75%</td>
</tr>
<tr>
<td>niid</td>
<td>fedrecon</td>
<td>50.35%</td>
</tr>
<tr>
<td>niid</td>
<td>fedchain+fedrecon</td>
<td>38.14%</td>
</tr>
<tr>
<td>niid</td>
<td>fedchain+fedrecon(改)</td>
<td>42.58%</td>
</tr>
</tbody></table>
<p><strong>数据集:  eminist</strong></p>
<table>
<thead>
<tr>
<th>数据分布</th>
<th>算法</th>
<th>精度</th>
</tr>
</thead>
<tbody><tr>
<td>iid</td>
<td>fedchain</td>
<td>96.89%</td>
</tr>
<tr>
<td>iid</td>
<td>fedavg</td>
<td>97.43%</td>
</tr>
<tr>
<td>iid</td>
<td>fedrecon</td>
<td>98.00%</td>
</tr>
<tr>
<td>iid</td>
<td>fedchain+fedrecon</td>
<td>97.30%</td>
</tr>
<tr>
<td>iid</td>
<td>fedchain+fedrecon(改)</td>
<td>98.30%</td>
</tr>
<tr>
<td>niid</td>
<td>fedchain</td>
<td>97.88%</td>
</tr>
<tr>
<td>niid</td>
<td>fedavg</td>
<td>97%</td>
</tr>
<tr>
<td>niid</td>
<td>fedrecon</td>
<td>97.10%</td>
</tr>
<tr>
<td>niid</td>
<td>fedchain+fedrecon</td>
<td>93.85%</td>
</tr>
<tr>
<td>niin</td>
<td>fedchain+fedrecon(改)</td>
<td>94.98%</td>
</tr>
</tbody></table>
<ul>
<li><p><input checked="" disabled="" type="checkbox"> 
fedchain+ fedrecon + 元学习改进 (niid)</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedchain + fedrecon + 元学习 (niid)</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedchain + fedrecon （niid）</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedchain+ fedrecon + 元学习改进 (iid)</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedchain + fedrecon + 元学习 (iid)</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedchain + fedrecon （iid）</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedchain(实验结果)</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedchain(iid+niid) 代码</p>
</li>
<li><p><input disabled="" type="checkbox"> 
fedsgd (实验结果保存，local_epoch &#x3D; 1, batch_size &#x3D; ∞, n_client&#x3D;100)</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedsgd (iid+niid)代码</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedavg(实验结果保存, local_epoch &#x3D; 3, batch_size &#x3D; 64,n_client&#x3D;10)</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
fedavg(iid+nni) 代码</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
cifar10 model 调通</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
myArgs util 抽取</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
iid+niid 划分 util</p>
</li>
</ul>
<h2 id="fedSGD-iid"><a href="#fedSGD-iid" class="headerlink" title="fedSGD_iid"></a>fedSGD_iid</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> dataset_utils</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cifar10Model</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> myArgs <span class="keyword">import</span> myArgs</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_args</span>():</span><br><span class="line">    args = myArgs()</span><br><span class="line">    args.n_clients = <span class="number">100</span></span><br><span class="line">    args.BATCH_SIZE = sys.maxsize</span><br><span class="line">    args.local_epochs = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataset</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="comment"># 创建一个转换器，将torchvision数据集的输出范围[0,1]转换为归一化范围的张量[-1,1]。</span></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">24</span>, <span class="number">24</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    trainset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建测试集</span></span><br><span class="line">    testset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">False</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_model</span>(<span class="params">args,trainset</span>):</span><br><span class="line">    model = cifar10Model.cnn_cifar10(<span class="built_in">len</span>(trainset.classes),trainset.data[<span class="number">0</span>].shape[<span class="number">2</span>],args)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    writer = SummaryWriter()</span><br><span class="line">    <span class="comment"># 创建summary writer时，指定文件路径</span></span><br><span class="line">    writer = SummaryWriter(log_dir=<span class="string">&quot;fedsgd_iid&quot;</span>)</span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    args = init_args()</span><br><span class="line">    <span class="comment"># 获取数据集</span></span><br><span class="line">    trainset,testset = get_dataset(args)</span><br><span class="line">    <span class="comment"># 构造各个客户端的iid数据集</span></span><br><span class="line">    all_client_trainloaders= dataset_utils.get_all_clients_iid_dataloader_list(trainset,args)</span><br><span class="line">    <span class="comment"># 初始化全局模型</span></span><br><span class="line">    global_model = init_model(args,trainset)</span><br><span class="line">    global_model = global_model.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">    global_criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.BATCH_SIZE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化各个客户端上的模型</span></span><br><span class="line">    client_models = [ deepcopy(global_model).to(device=<span class="string">&quot;cuda:0&quot;</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的优化器</span></span><br><span class="line">    client_optimizers = [ torch.optim.SGD(client_models[i].parameters(), lr=<span class="number">0.01</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的损失函数</span></span><br><span class="line">    client_criterions = [ torch.nn.CrossEntropyLoss() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 开始训练</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.global_epochs):</span><br><span class="line">        <span class="comment"># 每个客户端进行本地训练</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            loss_list = []</span><br><span class="line">            accuracy_list = []</span><br><span class="line">            client_i_model = client_models[client_i]</span><br><span class="line">            client_i_optimizer = client_optimizers[client_i]</span><br><span class="line">            client_i_criterion = client_criterions[client_i]</span><br><span class="line">            <span class="keyword">for</span> local_epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.local_epochs):</span><br><span class="line">                <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(all_client_trainloaders[client_i]):</span><br><span class="line">                    inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">                    client_i_optimizer.zero_grad()</span><br><span class="line">                    outputs = client_i_model(inputs)</span><br><span class="line">                    loss = client_i_criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">                    loss_list.append(loss.item())</span><br><span class="line">                    accuracy_list.append(outputs.argmax(dim=<span class="number">1</span>).eq(targets).<span class="built_in">sum</span>().item() / <span class="built_in">len</span>(targets))</span><br><span class="line"></span><br><span class="line">                    loss.backward()</span><br><span class="line">                    client_i_optimizer.step()</span><br><span class="line">            client_models[client_i] = client_i_model</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Client &#123;&#125; | Global_Epoch &#123;&#125; | Loss &#123;:.4f&#125; | Accuracy &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(client_i, epoch, np.mean(loss_list), np.mean(accuracy_list)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每个客户端的模型参数进行平均</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            <span class="keyword">for</span> name, param <span class="keyword">in</span> client_models[client_i].named_parameters():</span><br><span class="line">                <span class="keyword">if</span> client_i == <span class="number">0</span>:</span><br><span class="line">                    global_model.state_dict()[name].data = param.data</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    global_model.state_dict()[name].data += param.data</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> global_model.named_parameters():</span><br><span class="line">            param.data /= args.n_clients</span><br><span class="line">        <span class="comment"># 测试全局模型</span></span><br><span class="line">        test_loss = <span class="number">0</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">                inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">                outputs = global_model(inputs)</span><br><span class="line">                loss = global_criterion(outputs, targets)</span><br><span class="line">                test_loss += loss.item()</span><br><span class="line">                _, predicted = outputs.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">                total += targets.size(<span class="number">0</span>)</span><br><span class="line">                correct += predicted.eq(targets).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;loss&#x27;</span>, test_loss / (batch_idx + <span class="number">1</span>), epoch)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;accuracy&#x27;</span>, <span class="number">100.</span> * correct / total, epoch)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)&#x27;</span></span><br><span class="line">                % (epoch, test_loss / (batch_idx + <span class="number">1</span>), <span class="number">100.</span> * correct / total, correct, total))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将全局模型的参数赋值给各个客户端</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            client_models[client_i].load_state_dict(global_model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            torch.save(global_model.state_dict(), <span class="string">&#x27;model_save/fedsgd_iid_&#123;&#125;.pth&#x27;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="fedSGD-niid"><a href="#fedSGD-niid" class="headerlink" title="fedSGD_niid"></a>fedSGD_niid</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> dataset_utils</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cifar10Model</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> myArgs <span class="keyword">import</span> myArgs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_args</span>():</span><br><span class="line">    args = myArgs()</span><br><span class="line">    args.n_clients = <span class="number">100</span></span><br><span class="line">    args.BATCH_SIZE = sys.maxsize</span><br><span class="line">    args.local_epochs = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataset</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="comment"># 创建一个转换器，将torchvision数据集的输出范围[0,1]转换为归一化范围的张量[-1,1]。</span></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">24</span>, <span class="number">24</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    trainset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建测试集</span></span><br><span class="line">    testset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">False</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_model</span>(<span class="params">args,trainset</span>):</span><br><span class="line">    model = cifar10Model.cnn_cifar10(<span class="built_in">len</span>(trainset.classes),trainset.data[<span class="number">0</span>].shape[<span class="number">2</span>],args)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试模型loss 和 准确率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">epoch,test_loader,model,model_criterion</span>):</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">            inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = model_criterion(outputs, targets)</span><br><span class="line">            test_loss += loss.item()</span><br><span class="line">            _, predicted = outputs.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">            total += targets.size(<span class="number">0</span>)</span><br><span class="line">            correct += predicted.eq(targets).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="keyword">return</span> test_loss / (batch_idx + <span class="number">1</span>), <span class="number">100.</span> * correct / total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    writer = SummaryWriter()</span><br><span class="line">    <span class="comment"># 创建summary writer时，指定文件路径</span></span><br><span class="line">    writer = SummaryWriter(log_dir=<span class="string">&quot;fedsgd_non_iid&quot;</span>)</span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    args = init_args()</span><br><span class="line">    <span class="comment"># 获取数据集</span></span><br><span class="line">    trainset,testset = get_dataset(args)</span><br><span class="line">    <span class="comment"># 构造各个客户端的niid数据集</span></span><br><span class="line">    all_client_trainloaders= dataset_utils.get_all_clients_niid_dataloader_list(trainset,args)</span><br><span class="line">    <span class="comment"># 初始化全局模型</span></span><br><span class="line">    global_model = init_model(args,trainset)</span><br><span class="line">    global_model = global_model.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">    global_criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.BATCH_SIZE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化各个客户端上的模型</span></span><br><span class="line">    client_models = [ deepcopy(global_model).to(device=<span class="string">&quot;cuda:0&quot;</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的优化器</span></span><br><span class="line">    client_optimizers = [ torch.optim.SGD(client_models[i].parameters(), lr=<span class="number">0.01</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的损失函数</span></span><br><span class="line">    client_criterions = [ torch.nn.CrossEntropyLoss() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 开始训练</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.global_epochs):</span><br><span class="line">        <span class="comment"># 每个客户端进行本地训练</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            loss_list = []</span><br><span class="line">            accuracy_list = []</span><br><span class="line">            client_i_model = client_models[client_i]</span><br><span class="line">            client_i_optimizer = client_optimizers[client_i]</span><br><span class="line">            client_i_criterion = client_criterions[client_i]</span><br><span class="line">            <span class="keyword">for</span> local_epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.local_epochs):</span><br><span class="line">                <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(all_client_trainloaders[client_i]):</span><br><span class="line">                    inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">                    client_i_optimizer.zero_grad()</span><br><span class="line">                    outputs = client_i_model(inputs)</span><br><span class="line">                    loss = client_i_criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">                    loss_list.append(loss.item())</span><br><span class="line">                    accuracy_list.append(outputs.argmax(dim=<span class="number">1</span>).eq(targets).<span class="built_in">sum</span>().item() / <span class="built_in">len</span>(targets))</span><br><span class="line"></span><br><span class="line">                    loss.backward()</span><br><span class="line">                    client_i_optimizer.step()</span><br><span class="line">            client_models[client_i] = client_i_model</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Client &#123;&#125; | Global_Epoch &#123;&#125; | Loss &#123;:.4f&#125; | Accuracy &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(client_i, epoch, np.mean(loss_list), np.mean(accuracy_list)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每个客户端的模型参数进行平均</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            <span class="keyword">for</span> name, param <span class="keyword">in</span> client_models[client_i].named_parameters():</span><br><span class="line">                <span class="keyword">if</span> client_i == <span class="number">0</span>:</span><br><span class="line">                    global_model.state_dict()[name].data = param.data</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    global_model.state_dict()[name].data += param.data</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> global_model.named_parameters():</span><br><span class="line">            param.data /= args.n_clients</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将全局模型的参数赋值给各个客户端</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            client_models[client_i].load_state_dict(global_model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在各个客户端上测试模型</span></span><br><span class="line">        loss_i, accuracy_i = test(epoch, test_loader, global_model, global_criterion)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;loss&#x27;</span>, loss_i, epoch)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;accuracy&#x27;</span>, accuracy_i, epoch)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Global_Epoch: %d | Loss: %.3f | Acc: %.3f%% &#x27;</span></span><br><span class="line">              % (epoch, loss_i, accuracy_i))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            torch.save(global_model.state_dict(), <span class="string">&quot;model_save/fedsgd_niid_&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="fedavg-iid"><a href="#fedavg-iid" class="headerlink" title="fedavg_iid"></a>fedavg_iid</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> dataset_utils</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cifar10Model</span><br><span class="line"><span class="keyword">from</span> myArgs <span class="keyword">import</span> myArgs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_args</span>():</span><br><span class="line">    args = myArgs()</span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataset</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="comment"># 创建一个转换器，将torchvision数据集的输出范围[0,1]转换为归一化范围的张量[-1,1]。</span></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">24</span>, <span class="number">24</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    trainset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建测试集</span></span><br><span class="line">    testset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">False</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_model</span>(<span class="params">args,trainset</span>):</span><br><span class="line">    model = cifar10Model.cnn_cifar10(<span class="built_in">len</span>(trainset.classes),trainset.data[<span class="number">0</span>].shape[<span class="number">2</span>],args)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    args = init_args()</span><br><span class="line">    <span class="comment"># 获取数据集</span></span><br><span class="line">    trainset,testset = get_dataset(args)</span><br><span class="line">    <span class="comment"># 构造各个客户端的iid数据集</span></span><br><span class="line">    all_client_trainloaders= dataset_utils.get_all_clients_iid_dataloader_list(trainset,args)</span><br><span class="line">    <span class="comment"># 初始化全局模型</span></span><br><span class="line">    global_model = init_model(args,trainset)</span><br><span class="line">    global_model = global_model.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">    global_criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.BATCH_SIZE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化各个客户端上的模型</span></span><br><span class="line">    client_models = [ deepcopy(global_model).to(device=<span class="string">&quot;cuda:0&quot;</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的优化器</span></span><br><span class="line">    client_optimizers = [ torch.optim.SGD(client_models[i].parameters(), lr=<span class="number">0.01</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的损失函数</span></span><br><span class="line">    client_criterions = [ torch.nn.CrossEntropyLoss() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 开始训练</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.global_epochs):</span><br><span class="line">        <span class="comment"># 每个客户端进行本地训练</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            loss_list = []</span><br><span class="line">            accuracy_list = []</span><br><span class="line">            client_i_model = client_models[client_i]</span><br><span class="line">            client_i_optimizer = client_optimizers[client_i]</span><br><span class="line">            client_i_criterion = client_criterions[client_i]</span><br><span class="line">            <span class="keyword">for</span> local_epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.local_epochs):</span><br><span class="line">                <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(all_client_trainloaders[client_i]):</span><br><span class="line">                    inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">                    client_i_optimizer.zero_grad()</span><br><span class="line">                    outputs = client_i_model(inputs)</span><br><span class="line">                    loss = client_i_criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">                    loss_list.append(loss.item())</span><br><span class="line">                    accuracy_list.append(outputs.argmax(dim=<span class="number">1</span>).eq(targets).<span class="built_in">sum</span>().item() / <span class="built_in">len</span>(targets))</span><br><span class="line"></span><br><span class="line">                    loss.backward()</span><br><span class="line">                    client_i_optimizer.step()</span><br><span class="line">            client_models[client_i] = client_i_model</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Client &#123;&#125; | Global_Epoch &#123;&#125; | Loss &#123;:.4f&#125; | Accuracy &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(client_i, epoch, np.mean(loss_list), np.mean(accuracy_list)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每个客户端的模型参数进行平均</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            <span class="keyword">for</span> name, param <span class="keyword">in</span> client_models[client_i].named_parameters():</span><br><span class="line">                <span class="keyword">if</span> client_i == <span class="number">0</span>:</span><br><span class="line">                    global_model.state_dict()[name].data = param.data</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    global_model.state_dict()[name].data += param.data</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> global_model.named_parameters():</span><br><span class="line">            param.data /= args.n_clients</span><br><span class="line">        <span class="comment"># 测试全局模型</span></span><br><span class="line">        test_loss = <span class="number">0</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">                inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">                outputs = global_model(inputs)</span><br><span class="line">                loss = global_criterion(outputs, targets)</span><br><span class="line">                test_loss += loss.item()</span><br><span class="line">                _, predicted = outputs.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">                total += targets.size(<span class="number">0</span>)</span><br><span class="line">                correct += predicted.eq(targets).<span class="built_in">sum</span>().item()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)&#x27;</span></span><br><span class="line">                % (epoch, test_loss / (batch_idx + <span class="number">1</span>), <span class="number">100.</span> * correct / total, correct, total))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将全局模型的参数赋值给各个客户端</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            client_models[client_i].load_state_dict(global_model.state_dict())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="fedavg-niid"><a href="#fedavg-niid" class="headerlink" title="fedavg_niid"></a>fedavg_niid</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> dataset_utils</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cifar10Model</span><br><span class="line"><span class="keyword">from</span> myArgs <span class="keyword">import</span> myArgs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_args</span>():</span><br><span class="line">    args = myArgs()</span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataset</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="comment"># 创建一个转换器，将torchvision数据集的输出范围[0,1]转换为归一化范围的张量[-1,1]。</span></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">24</span>, <span class="number">24</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    trainset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建测试集</span></span><br><span class="line">    testset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">False</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_model</span>(<span class="params">args,trainset</span>):</span><br><span class="line">    model = cifar10Model.cnn_cifar10(<span class="built_in">len</span>(trainset.classes),trainset.data[<span class="number">0</span>].shape[<span class="number">2</span>],args)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试模型loss 和 准确率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">epoch,test_loader,model,model_criterion</span>):</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">            inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = model_criterion(outputs, targets)</span><br><span class="line">            test_loss += loss.item()</span><br><span class="line">            _, predicted = outputs.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">            total += targets.size(<span class="number">0</span>)</span><br><span class="line">            correct += predicted.eq(targets).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="keyword">return</span> test_loss / (batch_idx + <span class="number">1</span>), <span class="number">100.</span> * correct / total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    args = init_args()</span><br><span class="line">    <span class="comment"># 获取数据集</span></span><br><span class="line">    trainset,testset = get_dataset(args)</span><br><span class="line">    <span class="comment"># 构造各个客户端的niid数据集</span></span><br><span class="line">    all_client_trainloaders= dataset_utils.get_all_clients_niid_dataloader_list(trainset,args)</span><br><span class="line">    <span class="comment"># 初始化全局模型</span></span><br><span class="line">    global_model = init_model(args,trainset)</span><br><span class="line">    global_model = global_model.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">    global_criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.BATCH_SIZE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化各个客户端上的模型</span></span><br><span class="line">    client_models = [ deepcopy(global_model).to(device=<span class="string">&quot;cuda:0&quot;</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的优化器</span></span><br><span class="line">    client_optimizers = [ torch.optim.SGD(client_models[i].parameters(), lr=<span class="number">0.01</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的损失函数</span></span><br><span class="line">    client_criterions = [ torch.nn.CrossEntropyLoss() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 开始训练</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.global_epochs):</span><br><span class="line">        <span class="comment"># 每个客户端进行本地训练</span></span><br><span class="line">        loss_all_list = []</span><br><span class="line">        accuracy_all_list = []</span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            loss_list = []</span><br><span class="line">            accuracy_list = []</span><br><span class="line">            client_i_model = client_models[client_i]</span><br><span class="line">            client_i_optimizer = client_optimizers[client_i]</span><br><span class="line">            client_i_criterion = client_criterions[client_i]</span><br><span class="line">            <span class="keyword">for</span> local_epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.local_epochs):</span><br><span class="line">                <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(all_client_trainloaders[client_i]):</span><br><span class="line">                    inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">                    client_i_optimizer.zero_grad()</span><br><span class="line">                    outputs = client_i_model(inputs)</span><br><span class="line">                    loss = client_i_criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">                    loss_list.append(loss.item())</span><br><span class="line">                    accuracy_list.append(outputs.argmax(dim=<span class="number">1</span>).eq(targets).<span class="built_in">sum</span>().item() / <span class="built_in">len</span>(targets))</span><br><span class="line"></span><br><span class="line">                    loss.backward()</span><br><span class="line">                    client_i_optimizer.step()</span><br><span class="line">            client_models[client_i] = client_i_model</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Client &#123;&#125; | Global_Epoch &#123;&#125; | Loss &#123;:.4f&#125; | Accuracy &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(client_i, epoch, np.mean(loss_list), np.mean(accuracy_list)))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在各个客户端上测试模型</span></span><br><span class="line">            loss_i,accuracy_i = test(epoch,test_loader,client_i_model,client_i_criterion)</span><br><span class="line">            loss_all_list.append(loss_i)</span><br><span class="line">            accuracy_all_list.append(accuracy_i)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每个客户端的模型参数进行平均</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            <span class="keyword">for</span> name, param <span class="keyword">in</span> client_models[client_i].named_parameters():</span><br><span class="line">                <span class="keyword">if</span> client_i == <span class="number">0</span>:</span><br><span class="line">                    global_model.state_dict()[name].data = param.data</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    global_model.state_dict()[name].data += param.data</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> global_model.named_parameters():</span><br><span class="line">            param.data /= args.n_clients</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将全局模型的参数赋值给各个客户端</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            client_models[client_i].load_state_dict(global_model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Global_Epoch: %d | Loss: %.3f | Acc: %.3f%% &#x27;</span></span><br><span class="line">              % (epoch, np.mean(loss_all_list), np.mean(accuracy_all_list)))</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="MyArgs-参数"><a href="#MyArgs-参数" class="headerlink" title="MyArgs 参数"></a>MyArgs 参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">myArgs</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.n_clients = <span class="number">10</span></span><br><span class="line">        self.n_class = <span class="number">10</span></span><br><span class="line">        self.BATCH_SIZE = <span class="number">64</span></span><br><span class="line">        self.dataset = <span class="string">&#x27;cifar10&#x27;</span></span><br><span class="line">        self.alpha = <span class="number">1.0</span></span><br><span class="line">        self.global_epochs = <span class="number">50</span></span><br><span class="line">        self.local_epochs = <span class="number">3</span></span><br></pre></td></tr></table></figure>





<h2 id="cifar-CNN-Model"><a href="#cifar-CNN-Model" class="headerlink" title="cifar CNN Model"></a>cifar CNN Model</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> Resize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">cnn_cifar10</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes, num_channels, args</span>):</span><br><span class="line">        <span class="built_in">super</span>(cnn_cifar10, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># self.resize = Resize((24, 24))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># padding的same策略</span></span><br><span class="line">        self.KERE_SIZE = <span class="number">5</span></span><br><span class="line">        self.PADDING = (self.KERE_SIZE - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        self.feature_extractor = nn.Sequential(</span><br><span class="line">            nn.Conv2d(num_channels, <span class="number">64</span>, kernel_size=self.KERE_SIZE, stride=<span class="number">1</span>, padding=self.PADDING),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.ZeroPad2d((<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>)), <span class="comment"># Equivalent of TensorFlow padding &#x27;SAME&#x27; for MaxPool2d</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>),</span><br><span class="line">            nn.LocalResponseNorm(<span class="number">4</span>, alpha=<span class="number">0.001</span>/<span class="number">9</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=self.KERE_SIZE, stride=<span class="number">1</span>, padding=self.PADDING),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.LocalResponseNorm(<span class="number">4</span>, alpha=<span class="number">0.001</span>/<span class="number">9</span>),</span><br><span class="line">            nn.ZeroPad2d((<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>)), <span class="comment"># Equivalent of TensorFlow padding &#x27;SAME&#x27; for MaxPool2d</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(<span class="number">64</span>*<span class="number">6</span>*<span class="number">6</span>, <span class="number">384</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">384</span>, <span class="number">192</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">192</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.feature_extractor(x)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>



<h2 id="dataUtils"><a href="#dataUtils" class="headerlink" title="dataUtils"></a>dataUtils</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.sampler <span class="keyword">import</span> SubsetRandomSampler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取 数据集 &#123; target1 -&gt; [index1,index2...], target2 -&gt; [index1,index2...] &#125; 的 map</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_class_index_list_map</span>(<span class="params">trainset</span>):</span><br><span class="line">    class_map = &#123;&#125;</span><br><span class="line">    <span class="comment"># 遍历数据集上所有数据的标签，将每个类别的索引存储在 class_map 中</span></span><br><span class="line">    <span class="keyword">for</span> index_of_target <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(trainset.targets)):</span><br><span class="line">        class_target = trainset.targets[index_of_target]</span><br><span class="line">        <span class="keyword">if</span> class_target <span class="keyword">not</span> <span class="keyword">in</span> class_map:</span><br><span class="line">            class_map[class_target] = []</span><br><span class="line">            class_map[class_target].append(index_of_target)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            class_map[class_target].append(index_of_target)</span><br><span class="line">    <span class="keyword">return</span> class_map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据 class_map 和 data_percents(每个类别在私有数据集上的占比) 构造出每个 client 的niid数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_clients_niid_dataloader_list</span>(<span class="params">trainset,args</span>):</span><br><span class="line">    all_client_trainloaders = []</span><br><span class="line">    class_map = get_class_index_list_map(trainset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计每个类别在总数据集上的占比</span></span><br><span class="line">    p_class_tmp = []</span><br><span class="line">    <span class="keyword">for</span> cls <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(trainset.classes)):</span><br><span class="line">        p_class_tmp.append(trainset.targets.count(cls))</span><br><span class="line">    p_class = torch.tensor(p_class_tmp, dtype=torch.float32)</span><br><span class="line">    p_class = p_class / <span class="built_in">len</span>(trainset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据每个类别在总数据集上的占比(即，入参：各个类别的浓度)，以及 alpah 构造出每个 client 在每个类别上的占比</span></span><br><span class="line">    data_percents = torch.distributions.dirichlet.Dirichlet(p_class * args.alpha).sample((args.n_clients,))</span><br><span class="line">    <span class="comment"># 根据迪利克雷分布矩阵，遍历构造出每个 client 的数据dataloader</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">        one_client_sample_data_percent_list = data_percents[i]</span><br><span class="line">        one_client_indices = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(args.n_class):</span><br><span class="line">            one_class_percent = one_client_sample_data_percent_list[j]</span><br><span class="line">            select_count = <span class="built_in">len</span>(class_map[j]) * one_class_percent</span><br><span class="line">            sub_index = np.random.choice(class_map[j], <span class="built_in">int</span>(select_count), replace=<span class="literal">False</span>)</span><br><span class="line">            one_client_indices.extend(sub_index)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构造出每个 client 的数据dataloader</span></span><br><span class="line">        train_sampler = SubsetRandomSampler(one_client_indices)</span><br><span class="line">        train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.BATCH_SIZE, sampler=train_sampler)</span><br><span class="line">        <span class="comment"># 将每个 client 的数据dataloader 存储在 all_client_trainloaders 中</span></span><br><span class="line">        all_client_trainloaders.append(train_loader)</span><br><span class="line">    <span class="keyword">return</span>  all_client_trainloaders</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据 class_map 和 data_percents(每个类别在私有数据集上的占比) 构造出每个 client 的iid数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_all_clients_iid_dataloader_list</span>(<span class="params">trainset,args</span>):</span><br><span class="line">    all_client_trainloaders = []</span><br><span class="line">    class_map = get_class_index_list_map(trainset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计每个类别在总数据集上的占比</span></span><br><span class="line">    p_class = []</span><br><span class="line">    <span class="keyword">for</span> cls <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(trainset.classes)):</span><br><span class="line">        p_class.append(trainset.targets.count(cls) / <span class="built_in">len</span>(trainset.targets))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 独立同分布</span></span><br><span class="line">    data_percents = [p_class <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    data_percents = torch.tensor(data_percents)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据独立同分布，遍历构造出每个 client 的数据dataloader</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">        one_client_sample_data_percent_list = data_percents[i]</span><br><span class="line">        one_client_indices = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(args.n_class):</span><br><span class="line">            one_class_percent = one_client_sample_data_percent_list[j]</span><br><span class="line">            select_count = <span class="built_in">len</span>(class_map[j]) * one_class_percent</span><br><span class="line">            sub_index = np.random.choice(class_map[j], <span class="built_in">int</span>(select_count), replace=<span class="literal">False</span>)</span><br><span class="line">            one_client_indices.extend(sub_index)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构造出每个 client 的数据dataloader</span></span><br><span class="line">        train_sampler = SubsetRandomSampler(one_client_indices)</span><br><span class="line">        train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.BATCH_SIZE, sampler=train_sampler)</span><br><span class="line">        <span class="comment"># 将每个 client 的数据dataloader 存储在 all_client_trainloaders 中</span></span><br><span class="line">        all_client_trainloaders.append(train_loader)</span><br><span class="line">    <span class="keyword">return</span>  all_client_trainloaders</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="fedChain"><a href="#fedChain" class="headerlink" title="fedChain"></a>fedChain</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> dataset_utils</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cifar10Model</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> myArgs <span class="keyword">import</span> myArgs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_args</span>():</span><br><span class="line">    args = myArgs()</span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dataset</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="comment"># 创建一个转换器，将torchvision数据集的输出范围[0,1]转换为归一化范围的张量[-1,1]。</span></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">24</span>, <span class="number">24</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    trainset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">True</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建测试集</span></span><br><span class="line">    testset = torchvision.datasets.CIFAR10(</span><br><span class="line">        root=<span class="string">&#x27;../src/data/CIFAR10/&#x27;</span>,</span><br><span class="line">        train=<span class="literal">False</span>,</span><br><span class="line">        download=<span class="literal">True</span>,</span><br><span class="line">        transform=transform,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_model</span>(<span class="params">args,trainset</span>):</span><br><span class="line">    model = cifar10Model.cnn_cifar10(<span class="built_in">len</span>(trainset.classes),trainset.data[<span class="number">0</span>].shape[<span class="number">2</span>],args)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one_span_train_and_save</span>(<span class="params">start_epoch, end_epoch,</span></span><br><span class="line"><span class="params">                            client_models, client_optimizers, client_criterions, all_client_trainloaders,</span></span><br><span class="line"><span class="params">                            global_model, global_criterion, test_loader,</span></span><br><span class="line"><span class="params">                            args, writer</span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch, end_epoch):</span><br><span class="line">        <span class="comment"># 每个客户端进行本地训练</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            loss_list = []</span><br><span class="line">            accuracy_list = []</span><br><span class="line">            client_i_model = client_models[client_i]</span><br><span class="line">            client_i_optimizer = client_optimizers[client_i]</span><br><span class="line">            client_i_criterion = client_criterions[client_i]</span><br><span class="line">            <span class="keyword">for</span> local_epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.local_epochs):</span><br><span class="line">                <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(all_client_trainloaders[client_i]):</span><br><span class="line">                    inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">                    client_i_optimizer.zero_grad()</span><br><span class="line">                    outputs = client_i_model(inputs)</span><br><span class="line">                    loss = client_i_criterion(outputs, targets)</span><br><span class="line"></span><br><span class="line">                    loss_list.append(loss.item())</span><br><span class="line">                    accuracy_list.append(outputs.argmax(dim=<span class="number">1</span>).eq(targets).<span class="built_in">sum</span>().item() / <span class="built_in">len</span>(targets))</span><br><span class="line"></span><br><span class="line">                    loss.backward()</span><br><span class="line">                    client_i_optimizer.step()</span><br><span class="line">            client_models[client_i] = client_i_model</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Client &#123;&#125; | Global_Epoch &#123;&#125; | Loss &#123;:.4f&#125; | Accuracy &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(client_i, epoch,</span><br><span class="line">                                                                                       np.mean(loss_list),</span><br><span class="line">                                                                                       np.mean(accuracy_list)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每个客户端的模型参数进行平均</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            <span class="keyword">for</span> name, param <span class="keyword">in</span> client_models[client_i].named_parameters():</span><br><span class="line">                <span class="keyword">if</span> client_i == <span class="number">0</span>:</span><br><span class="line">                    global_model.state_dict()[name].data = param.data</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    global_model.state_dict()[name].data += param.data</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> global_model.named_parameters():</span><br><span class="line">            param.data /= args.n_clients</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 测试全局模型</span></span><br><span class="line">        test_loss = <span class="number">0</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">                inputs, targets = inputs.to(device=<span class="string">&quot;cuda:0&quot;</span>), targets.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">                outputs = global_model(inputs)</span><br><span class="line">                loss = global_criterion(outputs, targets)</span><br><span class="line">                test_loss += loss.item()</span><br><span class="line">                _, predicted = outputs.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">                total += targets.size(<span class="number">0</span>)</span><br><span class="line">                correct += predicted.eq(targets).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;loss&#x27;</span>, test_loss / (batch_idx + <span class="number">1</span>), epoch)</span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;accuracy&#x27;</span>, <span class="number">100.</span> * correct / total, epoch)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Global_Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)&#x27;</span></span><br><span class="line">              % (epoch, test_loss / (batch_idx + <span class="number">1</span>), <span class="number">100.</span> * correct / total, correct, total))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将全局模型的参数赋值给各个客户端</span></span><br><span class="line">        <span class="keyword">for</span> client_i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients):</span><br><span class="line">            client_models[client_i].load_state_dict(global_model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            torch.save(global_model.state_dict(), <span class="string">&#x27;model_save/fedchain_iid_&#123;&#125;.pth&#x27;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    writer = SummaryWriter()</span><br><span class="line">    <span class="comment"># 创建summary writer时，指定文件路径</span></span><br><span class="line">    writer = SummaryWriter(log_dir=<span class="string">&quot;fedchain_iid&quot;</span>)</span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    args = init_args()</span><br><span class="line">    <span class="comment"># 获取数据集</span></span><br><span class="line">    trainset,testset = get_dataset(args)</span><br><span class="line">    <span class="comment"># 构造各个客户端的iid数据集</span></span><br><span class="line">    all_client_trainloaders= dataset_utils.get_all_clients_iid_dataloader_list(trainset,args)</span><br><span class="line">    <span class="comment"># 初始化全局模型</span></span><br><span class="line">    global_model = init_model(args,trainset)</span><br><span class="line">    global_model = global_model.to(device=<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">    global_criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.BATCH_SIZE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化各个客户端上的模型</span></span><br><span class="line">    client_models = [ deepcopy(global_model).to(device=<span class="string">&quot;cuda:0&quot;</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的优化器</span></span><br><span class="line">    client_optimizers = [ torch.optim.SGD(client_models[i].parameters(), lr=<span class="number">0.01</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># 初始化各个客户端的损失函数</span></span><br><span class="line">    client_criterions = [ torch.nn.CrossEntropyLoss() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.n_clients)]</span><br><span class="line">    <span class="comment"># ##### step 1: FedAVG 开始训练  #####</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;##### step 1: FedAVG 开始训练  ##### &quot;</span>)</span><br><span class="line">    one_span_train_and_save(<span class="number">0</span>, args.fed_avg_epochs,</span><br><span class="line">                            client_models, client_optimizers, client_criterions, all_client_trainloaders,</span><br><span class="line">                            global_model, global_criterion, test_loader,</span><br><span class="line">                            args, writer</span><br><span class="line">                            )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;##### step 1: FedAVG 训练结束  ##### &quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ##### step 2: 参数切换到 FedSGD  #####</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;##### step 2: 参数切换到 FedSGD  ##### &quot;</span>)</span><br><span class="line">    args.local_epochs = <span class="number">1</span></span><br><span class="line">    args.BATCH_SIZE = sys.maxsize</span><br><span class="line">    all_client_trainloaders = dataset_utils.get_all_clients_iid_dataloader_list(trainset, args)</span><br><span class="line">    test_loader = torch.utils.data.DataLoader(testset, batch_size=args.BATCH_SIZE)</span><br><span class="line">    <span class="built_in">print</span>(args)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ##### step 3: FedSGD 开始训练  #####</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;##### step 3: FedSGD 开始训练  ##### &quot;</span>)</span><br><span class="line">    one_span_train_and_save(args.fed_avg_epochs, args.global_epochs,</span><br><span class="line">                            client_models, client_optimizers, client_criterions, all_client_trainloaders,</span><br><span class="line">                            global_model, global_criterion, test_loader,</span><br><span class="line">                            args, writer</span><br><span class="line">                            )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;##### step 3: FedSGD 训练结束  ##### &quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="FedRecon"><a href="#FedRecon" class="headerlink" title="FedRecon"></a>FedRecon</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">sys.path.append(<span class="string">&quot;/&quot;</span>)</span><br><span class="line">sys.path.append(<span class="string">&quot;data&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> data.utils <span class="keyword">import</span> get_dataset</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> train_with_logging</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> random_split, DataLoader</span><br><span class="line"><span class="keyword">from</span> path <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line">PROJECT_DIR = Path(__file__).parent.parent.abspath()</span><br><span class="line">CLIENTS_DIR = PROJECT_DIR / <span class="string">&quot;clients&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FedReconTrainer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args, model, logger</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        The function initializes the parameters of the model, and also initializes the dataloaders for</span></span><br><span class="line"><span class="string">        the support set, query set, and validation set</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">          args: the arguments passed to the main script</span></span><br><span class="line"><span class="string">          model: the model to be trained</span></span><br><span class="line"><span class="string">          logger: a logger object to log the training process</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> args.gpu <span class="keyword">and</span> torch.cuda.is_available():</span><br><span class="line">            self.device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.recon_epochs = args.recon_epochs</span><br><span class="line">        self.pers_epochs = args.pers_epochs</span><br><span class="line">        self.logger = logger</span><br><span class="line">        self.model = deepcopy(model)</span><br><span class="line">        self.backup_local_params = self.model.local_params(</span><br><span class="line">            requires_name=<span class="literal">True</span>, data_only=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        self.batch_size = args.batch_size</span><br><span class="line">        self.valset_ratio = args.valset_ratio</span><br><span class="line">        self.dataset = args.dataset</span><br><span class="line">        self.criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">        self.recon_lr = args.recon_lr</span><br><span class="line">        self.pers_lr = args.pers_lr</span><br><span class="line">        self.no_split = args.no_split</span><br><span class="line"></span><br><span class="line">        self.<span class="built_in">id</span> = <span class="literal">None</span></span><br><span class="line">        self.support_set_dataloader = <span class="literal">None</span></span><br><span class="line">        self.query_set_dataloader = <span class="literal">None</span></span><br><span class="line">        self.val_set_dataloader = <span class="literal">None</span></span><br><span class="line">        self.weight = <span class="number">0</span></span><br><span class="line">        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, client_id, model_params, have_seen=<span class="literal">False</span>, validation=<span class="literal">False</span>, global_epoch=<span class="number">50</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        The function takes in the client id, the model parameters, and a boolean value indicating whether</span></span><br><span class="line"><span class="string">        the client has been trained before. If the client has been trained before, the function loads</span></span><br><span class="line"><span class="string">        the client data. Otherwise, the function splits the dataset and loads the backup local</span></span><br><span class="line"><span class="string">        parameters. The function then calculates the model difference and trains the model with logging.</span></span><br><span class="line"><span class="string">        The function then calculates the pseudo gradients and saves the client data. The function returns</span></span><br><span class="line"><span class="string">        the model difference and the weight</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">          client_id: the id of the client</span></span><br><span class="line"><span class="string">          model_params: the global model parameters</span></span><br><span class="line"><span class="string">          have_seen: whether the client has been trained before. Defaults to False</span></span><br><span class="line"><span class="string">          validation: whether to use the validation set or not. Defaults to False</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">          The model_diff is the difference between the global model and the local model.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.<span class="built_in">id</span> = client_id</span><br><span class="line">        self.model.load_state_dict(model_params, strict=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> have_seen:</span><br><span class="line">            self.load_client_data(client_id)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.split_dataset()</span><br><span class="line">            self.model.load_state_dict(self.backup_local_params, strict=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.<span class="built_in">id</span> = client_id</span><br><span class="line">        model_diff = self.model.global_params(requires_name=<span class="literal">True</span>, data_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        res_map = train_with_logging(self, validation)()</span><br><span class="line">        loss_after = res_map[<span class="string">&quot;loss_after&quot;</span>]</span><br><span class="line">        acc_after = res_map[<span class="string">&quot;acc_after&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate the pseudo gradients</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> frz_p, updated_p <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                model_diff.values(), self.model.global_params()</span><br><span class="line">            ):</span><br><span class="line">                frz_p.sub_(updated_p)</span><br><span class="line"></span><br><span class="line">        self.save_client_data()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> model_diff, self.weight, loss_after, acc_after</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_train</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        &gt; For each epoch, we first train the local model on the support set, then we train the global model</span></span><br><span class="line"><span class="string">        on the query set</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        all_loss = []</span><br><span class="line">        all_acc = []</span><br><span class="line">        <span class="comment"># reconstruction phase</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.recon_epochs):</span><br><span class="line">            <span class="keyword">for</span> x, y <span class="keyword">in</span> self.support_set_dataloader:</span><br><span class="line">                x, y = x.to(self.device), y.to(self.device)</span><br><span class="line">                logit = self.model(x)</span><br><span class="line">                loss = self.criterion(logit, y)</span><br><span class="line">                gradients = torch.autograd.grad(loss, self.model.local_params())</span><br><span class="line">                <span class="keyword">for</span> param, grad <span class="keyword">in</span> <span class="built_in">zip</span>(self.model.local_params(), gradients):</span><br><span class="line">                    param.data -= self.recon_lr * grad</span><br><span class="line"></span><br><span class="line">        <span class="comment"># personalzation phase</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.pers_epochs):</span><br><span class="line">            <span class="keyword">for</span> x, y <span class="keyword">in</span> self.query_set_dataloader:</span><br><span class="line">                x, y = x.to(self.device), y.to(self.device)</span><br><span class="line">                logit = self.model(x)</span><br><span class="line">                loss = self.criterion(logit, y)</span><br><span class="line"></span><br><span class="line">                all_loss.append(loss.item())</span><br><span class="line">                all_acc.append((logit.argmax(dim=<span class="number">1</span>) == y).<span class="built_in">float</span>().mean().item())</span><br><span class="line"></span><br><span class="line">                self.optimizer.zero_grad()</span><br><span class="line">                loss.backward()</span><br><span class="line">                self.optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.mean(all_loss), np.mean(all_acc)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eval</span>(<span class="params">self, model_params, client_id</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        The function takes in the model parameters and the client id, and then loads the model</span></span><br><span class="line"><span class="string">        parameters into the model, and then loads the backup local parameters into the model, and then</span></span><br><span class="line"><span class="string">        splits the dataset, and then returns the result of the train_with_logging function</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">          model_params: the model parameters to be evaluated</span></span><br><span class="line"><span class="string">          client_id: the id of the client</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">          The return value is the validation loss.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.<span class="built_in">id</span> = client_id</span><br><span class="line"></span><br><span class="line">        self.model.load_state_dict(model_params, strict=<span class="literal">False</span>)</span><br><span class="line">        self.model.load_state_dict(self.backup_local_params, strict=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.split_dataset()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> train_with_logging(self, validation=<span class="literal">True</span>)()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">split_dataset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        The function splits the dataset into training, validation and test sets.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        dataset = get_dataset(self.dataset, self.<span class="built_in">id</span>)</span><br><span class="line"></span><br><span class="line">        num_val_samples = <span class="built_in">int</span>(self.valset_ratio * <span class="built_in">len</span>(dataset))</span><br><span class="line">        num_train_samples = <span class="built_in">len</span>(dataset) - num_val_samples</span><br><span class="line"></span><br><span class="line">        training_set, val_set = random_split(</span><br><span class="line">            dataset, [num_train_samples, num_val_samples]</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> self.no_split:</span><br><span class="line">            num_support_samples = num_query_samples = num_train_samples</span><br><span class="line">            support_set = query_set = training_set</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># query set&#x27;s size is set same as the support set&#x27;s by default.</span></span><br><span class="line">            num_support_samples = <span class="built_in">int</span>(num_train_samples / <span class="number">2</span>)</span><br><span class="line">            num_query_samples = num_train_samples - num_support_samples</span><br><span class="line">            support_set, query_set = random_split(</span><br><span class="line">                training_set, [num_support_samples, num_query_samples]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        self.support_set_dataloader = DataLoader(support_set, self.batch_size)</span><br><span class="line">        self.query_set_dataloader = DataLoader(query_set, self.batch_size)</span><br><span class="line">        self.val_set_dataloader = DataLoader(val_set, self.batch_size)</span><br><span class="line">        self.weight = num_query_samples</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_client_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        It saves the client&#x27;s data, weight, and local parameters to a pickle file</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        local_params = self.model.local_params(requires_name=<span class="literal">True</span>, data_only=<span class="literal">True</span>)</span><br><span class="line">        pkl_path = CLIENTS_DIR / <span class="string">f&quot;<span class="subst">&#123;self.<span class="built_in">id</span>&#125;</span>.pkl&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(pkl_path, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            pickle.dump(</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">&quot;support&quot;</span>: self.support_set_dataloader,</span><br><span class="line">                    <span class="string">&quot;query&quot;</span>: self.query_set_dataloader,</span><br><span class="line">                    <span class="string">&quot;val&quot;</span>: self.val_set_dataloader,</span><br><span class="line">                    <span class="string">&quot;weight&quot;</span>: self.weight,</span><br><span class="line">                    <span class="string">&quot;local_params&quot;</span>: local_params,</span><br><span class="line">                &#125;,</span><br><span class="line">                f,</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_client_data</span>(<span class="params">self, client_id</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        It loads the client data from a pickle file, and then sets the support, query, and validation</span></span><br><span class="line"><span class="string">        dataloaders, as well as the weight and local parameters of the model</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">          client_id: the id of the client we want to load data for</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        pkl_path = CLIENTS_DIR / <span class="string">f&quot;<span class="subst">&#123;client_id&#125;</span>.pkl&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(pkl_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            client_data = pickle.load(f)</span><br><span class="line">        self.support_set_dataloader = client_data[<span class="string">&quot;support&quot;</span>]</span><br><span class="line">        self.query_set_dataloader = client_data[<span class="string">&quot;query&quot;</span>]</span><br><span class="line">        self.val_set_dataloader = client_data[<span class="string">&quot;val&quot;</span>]</span><br><span class="line">        self.weight = client_data[<span class="string">&quot;weight&quot;</span>]</span><br><span class="line">        local_params = client_data[<span class="string">&quot;local_params&quot;</span>]</span><br><span class="line">        self.model.load_state_dict(local_params, strict=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/01/05/excludes-rubbish-websites/" rel="prev" title="排除垃圾网站">
                  <i class="fa fa-angle-left"></i> 排除垃圾网站
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/02/11/telegram-openai-chatbot/" rel="next" title="ChatGPT的机器人">
                  ChatGPT的机器人 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Promise Chan</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div><a href="https://icp.gov.moe/?keyword=20180708" rel="external nofollow noreferrer" target="_blank" data-pjax-state="" style="
    border-bottom-width: 0px;
">萌 ICP 备 20180708 号</a>
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/10/2022 22:00:00");//此处修改你的建站时间，注意格式
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "小站在混沌中存活了 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
