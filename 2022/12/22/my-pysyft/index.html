<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">

<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="pysyft 学习专栏">
<meta property="og:type" content="article">
<meta property="og:title" content="pysyft学习">
<meta property="og:url" content="http://example.com/2022/12/22/my-pysyft/index.html">
<meta property="og:site_name" content="PromiseChanの博客">
<meta property="og:description" content="pysyft 学习专栏">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-12-22T15:30:19.000Z">
<meta property="article:modified_time" content="2022-12-31T09:49:48.822Z">
<meta property="article:author" content="Promise Chan">
<meta property="article:tag" content="心得">
<meta property="article:tag" content="pysyft">
<meta property="article:tag" content="实战">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2022/12/22/my-pysyft/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>pysyft学习 | PromiseChanの博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">PromiseChanの博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-fa fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-fa fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-fa fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-fa fa-th"></i>分类</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/12/22/my-pysyft/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="Promise Chan">
      <meta itemprop="description" content="Coding & upgrading">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PromiseChanの博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          pysyft学习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-22 23:30:19" itemprop="dateCreated datePublished" datetime="2022-12-22T23:30:19+08:00">2022-12-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-31 17:49:48" itemprop="dateModified" datetime="2022-12-31T17:49:48+08:00">2022-12-31</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>pysyft 学习专栏</p>
<span id="more"></span>

<h2 id="1-环境搭建"><a href="#1-环境搭建" class="headerlink" title="1.环境搭建"></a>1.环境搭建</h2><p>pysyft 目前不是稳定的框架，因此选择了经典的0.2.9版本</p>
<p>因为0.2.x 版本有完善的github文档</p>
<h3 id="1-python-3-7"><a href="#1-python-3-7" class="headerlink" title="(1)python-3.7"></a>(1)python-3.7</h3><p>pysyft最新0.2.x(0.2.9)，网上经常说的3.6 不行，会报其他依赖需要python&gt;&#x3D;3.7.x</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n env_pysyft python=3.7</span><br></pre></td></tr></table></figure>

<h3 id="2-pytorch-1-4-0"><a href="#2-pytorch-1-4-0" class="headerlink" title="(2) pytorch-1.4.0"></a>(2) pytorch-1.4.0</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate env_pysyft</span><br><span class="line">conda install pytorch==1.4.0 torchvision==0.5.0 cpuonly -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br></pre></td></tr></table></figure>

<h3 id="3-syft-0-2-9"><a href="#3-syft-0-2-9" class="headerlink" title="(3) syft-0.2.9"></a>(3) syft-0.2.9</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install syft==0.2.9  -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>

<h3 id="4-protobuf-3-20-3"><a href="#4-protobuf-3-20-3" class="headerlink" title="(4)   protobuf-3.20.3"></a>(4)   protobuf-3.20.3</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># </span><span class="language-bash">syft 需要低版本 protobuf, 但是pytorch-1.4.0 用的是高版本</span></span><br><span class="line"><span class="meta"># </span><span class="language-bash">需要 3.19.0 &lt;= protobuf &lt;=3.20.x</span></span><br><span class="line">pip uninstall protobug</span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple protobuf==3.20.3</span><br></pre></td></tr></table></figure>

<p>至此，安装完 pysyft-0.2.9 环境</p>
<h2 id="2-demo-验证"><a href="#2-demo-验证" class="headerlink" title="2. demo 验证"></a>2. demo 验证</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Parameter</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> syft <span class="keyword">as</span> sy</span><br><span class="line"><span class="comment"># 创建本地hook，用于连接远程存放数据的服务器</span></span><br><span class="line">hook = sy.TorchHook(torch)</span><br><span class="line"><span class="comment"># 创建一个名为bob的存放数据的服务器</span></span><br><span class="line">bob = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;bob&quot;</span>)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">y = torch.tensor([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 操作的是 x的指针，x数据在 bob 机器上</span></span><br><span class="line">x_ptr = x.send(bob)</span><br><span class="line"><span class="comment"># 操作的是 y 的指针，y数据在 bob 机器上</span></span><br><span class="line">y_ptr = y.send(bob)</span><br><span class="line"><span class="comment"># 定义需要优化的目标函数</span></span><br><span class="line">z = x_ptr + x_ptr</span><br><span class="line"><span class="comment"># 获取目标函数运算后的结果</span></span><br><span class="line"><span class="built_in">print</span>(z.get())</span><br><span class="line"><span class="comment"># 发出反向传播命令</span></span><br><span class="line">z.backward()</span><br><span class="line"><span class="comment"># 获取x 的梯度</span></span><br><span class="line">x = x.get()</span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br></pre></td></tr></table></figure>

<h2 id="3-联邦学习简单案例"><a href="#3-联邦学习简单案例" class="headerlink" title="3. 联邦学习简单案例"></a>3. 联邦学习简单案例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">import</span> syft <span class="keyword">as</span> sy</span><br><span class="line"><span class="keyword">from</span> syft.federated.floptimizer <span class="keyword">import</span> Optims</span><br><span class="line"></span><br><span class="line">hook = sy.TorchHook(torch)</span><br><span class="line"><span class="comment"># create a couple workers</span></span><br><span class="line">workers = [<span class="string">&#x27;bob&#x27;</span>, <span class="string">&#x27;alice&#x27;</span>]</span><br><span class="line">bob = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;bob&quot;</span>)</span><br><span class="line">alice = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;alice&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># A Toy Dataset</span></span><br><span class="line">data = torch.tensor([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.tensor([[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get pointers to training data on each worker by</span></span><br><span class="line"><span class="comment"># sending some training data to bob and alice</span></span><br><span class="line">data_bob = data[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">target_bob = target[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">data_alice = data[<span class="number">2</span>:]</span><br><span class="line">target_alice = target[<span class="number">2</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iniitalize A Toy Model</span></span><br><span class="line">model = nn.Linear(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">data_bob = data_bob.send(bob)</span><br><span class="line">data_alice = data_alice.send(alice)</span><br><span class="line">target_bob = target_bob.send(bob)</span><br><span class="line">target_alice = target_alice.send(alice)</span><br><span class="line"></span><br><span class="line"><span class="comment"># organize pointers into a list</span></span><br><span class="line">datasets = [(data_bob,target_bob),(data_alice,target_alice)]</span><br><span class="line"></span><br><span class="line">optims = Optims(workers, optim=optim.Adam(params=model.parameters(),lr=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    <span class="comment"># Training Logic</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># NEW) iterate through each worker&#x27;s dataset</span></span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> datasets:</span><br><span class="line">            <span class="comment"># NEW) send model to correct worker</span></span><br><span class="line">            model.send(data.location)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Call the optimizer for the worker using get_optim</span></span><br><span class="line">            opt = optims.get_optim(data.location.<span class="built_in">id</span>)</span><br><span class="line">            <span class="comment"># print(data.location.id)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 1) erase previous gradients (if they exist)</span></span><br><span class="line">            opt.zero_grad()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2) make a prediction</span></span><br><span class="line">            pred = model(data)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3) calculate how much we missed</span></span><br><span class="line">            loss = ((pred - target) ** <span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4) figure out which weights caused us to miss</span></span><br><span class="line">            loss.backward()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 5) change those weights</span></span><br><span class="line">            opt.step()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># NEW) get model (with gradients)</span></span><br><span class="line">            model.get()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 6) print our progress</span></span><br><span class="line">            <span class="built_in">print</span>(loss.get().data)  <span class="comment"># NEW) slight edit... need to call .get() on loss\</span></span><br><span class="line">            </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    train()</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="4-FedAvg"><a href="#4-FedAvg" class="headerlink" title="4. FedAvg"></a>4. FedAvg</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> syft <span class="keyword">as</span> sy</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">hook = sy.TorchHook(torch)</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># create a couple workers</span></span><br><span class="line"></span><br><span class="line">bob = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;bob&quot;</span>)</span><br><span class="line">alice = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;alice&quot;</span>)</span><br><span class="line">secure_worker = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;secure_worker&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># A Toy Dataset</span></span><br><span class="line">data = torch.tensor([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line">target = torch.tensor([[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get pointers to training data on each worker by</span></span><br><span class="line"><span class="comment"># sending some training data to bob and alice</span></span><br><span class="line">bobs_data = data[<span class="number">0</span>:<span class="number">2</span>].send(bob)</span><br><span class="line">bobs_target = target[<span class="number">0</span>:<span class="number">2</span>].send(bob)</span><br><span class="line"></span><br><span class="line">alices_data = data[<span class="number">2</span>:].send(alice)</span><br><span class="line">alices_target = target[<span class="number">2</span>:].send(alice)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iniitalize A Toy Model</span></span><br><span class="line">model = nn.Linear(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">bobs_model = model.copy().send(bob)</span><br><span class="line">alices_model = model.copy().send(alice)</span><br><span class="line"></span><br><span class="line">bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=<span class="number">0.1</span>)</span><br><span class="line">alices_opt = optim.SGD(params=alices_model.parameters(),lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">iterations = <span class="number">10</span></span><br><span class="line">worker_iters = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> a_iter <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line"></span><br><span class="line">    bobs_model = model.copy().send(bob)</span><br><span class="line">    alices_model = model.copy().send(alice)</span><br><span class="line"></span><br><span class="line">    bobs_opt = optim.SGD(params=bobs_model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">    alices_opt = optim.SGD(params=alices_model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> wi <span class="keyword">in</span> <span class="built_in">range</span>(worker_iters):</span><br><span class="line">        <span class="comment"># Train Bob&#x27;s Model</span></span><br><span class="line">        bobs_opt.zero_grad()</span><br><span class="line">        bobs_pred = bobs_model(bobs_data)</span><br><span class="line">        bobs_loss = ((bobs_pred - bobs_target) ** <span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">        bobs_loss.backward()</span><br><span class="line"></span><br><span class="line">        bobs_opt.step()</span><br><span class="line">        bobs_loss = bobs_loss.get().data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Train Alice&#x27;s Model</span></span><br><span class="line">        alices_opt.zero_grad()</span><br><span class="line">        alices_pred = alices_model(alices_data)</span><br><span class="line">        alices_loss = ((alices_pred - alices_target) ** <span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line">        alices_loss.backward()</span><br><span class="line"></span><br><span class="line">        alices_opt.step()</span><br><span class="line">        alices_loss = alices_loss.get().data</span><br><span class="line"></span><br><span class="line">    alices_model.move(secure_worker)</span><br><span class="line">    bobs_model.move(secure_worker)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        model.weight.set_(((alices_model.weight.data + bobs_model.weight.data) / <span class="number">2</span>).get())</span><br><span class="line">        model.bias.set_(((alices_model.bias.data + bobs_model.bias.data) / <span class="number">2</span>).get())</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Bob:&quot;</span> + <span class="built_in">str</span>(bobs_loss) + <span class="string">&quot; Alice:&quot;</span> + <span class="built_in">str</span>(alices_loss))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">preds = model(data)</span><br><span class="line">loss = ((preds - target) ** <span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(preds)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line"><span class="built_in">print</span>(loss.data)</span><br></pre></td></tr></table></figure>

<h2 id="5-使用fedsgd训练-CNN-网络"><a href="#5-使用fedsgd训练-CNN-网络" class="headerlink" title="5.使用fedsgd训练  CNN 网络"></a>5.使用fedsgd训练  CNN 网络</h2><h3 id="与单机版训练的区别"><a href="#与单机版训练的区别" class="headerlink" title="与单机版训练的区别"></a>与单机版训练的区别</h3><ol>
<li><p>dataloader</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实际是将minist 拆分成两份 ，一份给 bob，一份给 alice</span></span><br><span class="line"><span class="comment"># &lt;-- this is now a FederatedDataLoader</span></span><br><span class="line">federated_train_loader = sy.FederatedDataLoader( </span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                   transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ]))</span><br><span class="line">    .federate((bob, alice)), <span class="comment"># &lt;-- NEW: we distribute the dataset across all the workers, </span></span><br></pre></td></tr></table></figure>


</li>
<li><p>模型训练前，分发给各个客户端，在客户端上进行实际训练</p>
</li>
</ol>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  for batch_idx, (data, target)</span></span><br><span class="line"><span class="comment">#  这一段相当于对两份Part-minist整合成一个Big-minist</span></span><br><span class="line"><span class="comment">#  然后按 batch_size  遍历 Big-minist</span></span><br><span class="line"><span class="comment">#  因此实际一个全局 epoch 训练流程如下 : </span></span><br><span class="line"><span class="comment">#  epoch_1 &amp;&amp; batch_id_1 &amp;&amp; model.send(bob) &amp;&amp; loss.backward() </span></span><br><span class="line"><span class="comment">#  epoch_1 &amp;&amp; batch_id_2 &amp;&amp; model.send(bob) &amp;&amp; loss.backward()   </span></span><br><span class="line"><span class="comment">#  ...  </span></span><br><span class="line"><span class="comment">#  epoch_1 &amp;&amp; batch_id_1 &amp;&amp; model.send(alice) &amp;&amp; loss.backward()  </span></span><br><span class="line"><span class="comment">#  epoch_1 &amp;&amp; batch_id_2 &amp;&amp; model.send(alice) &amp;&amp; loss.backward()  </span></span><br><span class="line"><span class="comment">#  ...</span></span><br><span class="line"><span class="comment"># &lt;-- now it is a distributed dataset</span></span><br><span class="line"><span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(federated_train_loader): </span><br><span class="line">    model.send(data.location) <span class="comment"># &lt;-- NEW: send the model to the right location</span></span><br><span class="line">    data, target = data.to(device), target.to(device)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<h3 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> syft <span class="keyword">as</span> sy  <span class="comment"># &lt;-- NEW: import the Pysyft library</span></span><br><span class="line">hook = sy.TorchHook(torch)  <span class="comment"># &lt;-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning</span></span><br><span class="line">bob = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;bob&quot;</span>)  <span class="comment"># &lt;-- NEW: define remote worker bob</span></span><br><span class="line">alice = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;alice&quot;</span>)  <span class="comment"># &lt;-- NEW: and alice</span></span><br><span class="line">epochs =  <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Arguments</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.batch_size = <span class="number">64</span></span><br><span class="line">        self.test_batch_size = <span class="number">1000</span></span><br><span class="line">        self.epochs = epochs</span><br><span class="line">        self.lr = <span class="number">0.01</span></span><br><span class="line">        self.momentum = <span class="number">0.5</span></span><br><span class="line">        self.no_cuda = <span class="literal">False</span></span><br><span class="line">        self.seed = <span class="number">1</span></span><br><span class="line">        self.log_interval = <span class="number">30</span></span><br><span class="line">        self.save_model = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">args = Arguments()</span><br><span class="line"></span><br><span class="line">use_cuda = <span class="keyword">not</span> args.no_cuda <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">torch.manual_seed(args.seed)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">kwargs = &#123;<span class="string">&#x27;num_workers&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;pin_memory&#x27;</span>: <span class="literal">True</span>&#125; <span class="keyword">if</span> use_cuda <span class="keyword">else</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">federated_train_loader = sy.FederatedDataLoader( <span class="comment"># &lt;-- this is now a FederatedDataLoader</span></span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                   transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ]))</span><br><span class="line">    .federate((bob, alice)), <span class="comment"># &lt;-- NEW: we distribute the dataset across all the workers, it&#x27;s now a FederatedDataset</span></span><br><span class="line">    batch_size=args.batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=args.test_batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">50</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">4</span>*<span class="number">4</span>*<span class="number">50</span>, <span class="number">500</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">500</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = F.relu(self.conv2(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">4</span>*<span class="number">4</span>*<span class="number">50</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args, model, device, federated_train_loader, optimizer, epoch</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(federated_train_loader): <span class="comment"># &lt;-- now it is a distributed dataset</span></span><br><span class="line">        model.send(data.location) <span class="comment"># &lt;-- NEW: send the model to the right location</span></span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = F.nll_loss(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        model.get() <span class="comment"># &lt;-- NEW: get the model back</span></span><br><span class="line">        <span class="keyword">if</span> batch_idx % args.log_interval == <span class="number">0</span>:</span><br><span class="line">            loss = loss.get() <span class="comment"># &lt;-- NEW: get the loss back</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, batch_idx * args.batch_size, <span class="built_in">len</span>(federated_train_loader) * args.batch_size,</span><br><span class="line">                <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(federated_train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">args, model, device, test_loader</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            output = model(data)</span><br><span class="line">            test_loss += F.nll_loss(output, target, reduction=<span class="string">&#x27;sum&#x27;</span>).item() <span class="comment"># sum up batch loss</span></span><br><span class="line">            pred = output.argmax(<span class="number">1</span>, keepdim=<span class="literal">True</span>) <span class="comment"># get the index of the max log-probability</span></span><br><span class="line">            correct += pred.eq(target.view_as(pred)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net().to(device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=args.lr) <span class="comment"># TODO momentum is not supported at the moment</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.epochs + <span class="number">1</span>):</span><br><span class="line">    train(args, model, device, federated_train_loader, optimizer, epoch)</span><br><span class="line">    test(args, model, device, test_loader)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (args.save_model):</span><br><span class="line">    torch.save(model.state_dict(), <span class="string">&quot;mnist_cnn.pt&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="6-使用fedavg-训练CNN网络"><a href="#6-使用fedavg-训练CNN网络" class="headerlink" title="6.使用fedavg 训练CNN网络"></a>6.使用fedavg 训练CNN网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> syft <span class="keyword">as</span> sy  <span class="comment"># &lt;-- NEW: import the Pysyft library</span></span><br><span class="line">hook = sy.TorchHook(torch)  <span class="comment"># &lt;-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning</span></span><br><span class="line">bob = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;bob&quot;</span>)  <span class="comment"># &lt;-- NEW: define remote worker bob</span></span><br><span class="line">alice = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;alice&quot;</span>)  <span class="comment"># &lt;-- NEW: and alice</span></span><br><span class="line"></span><br><span class="line">workers  = &#123;&#125;</span><br><span class="line">workers[<span class="string">&#x27;bob&#x27;</span>] = bob</span><br><span class="line">workers[<span class="string">&#x27;alice&#x27;</span>] = alice</span><br><span class="line"></span><br><span class="line">secure_worker = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;secure_worker&quot;</span>)</span><br><span class="line"></span><br><span class="line">epochs =  <span class="number">10</span></span><br><span class="line">local_epochs =  <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Arguments</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.batch_size = <span class="number">64</span></span><br><span class="line">        self.test_batch_size = <span class="number">1000</span></span><br><span class="line">        self.epochs = epochs</span><br><span class="line">        self.lr = <span class="number">0.01</span></span><br><span class="line">        self.momentum = <span class="number">0.5</span></span><br><span class="line">        self.no_cuda = <span class="literal">False</span></span><br><span class="line">        self.seed = <span class="number">1</span></span><br><span class="line">        self.log_interval = <span class="number">30</span></span><br><span class="line">        self.save_model = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">args = Arguments()</span><br><span class="line"></span><br><span class="line">use_cuda = <span class="keyword">not</span> args.no_cuda <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">torch.manual_seed(args.seed)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">kwargs = &#123;<span class="string">&#x27;num_workers&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;pin_memory&#x27;</span>: <span class="literal">True</span>&#125; <span class="keyword">if</span> use_cuda <span class="keyword">else</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">federated_train_loader = sy.FederatedDataLoader( <span class="comment"># &lt;-- this is now a FederatedDataLoader</span></span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">                   transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ]))</span><br><span class="line">    .federate((bob, alice)), <span class="comment"># &lt;-- NEW: we distribute the dataset across all the workers, it&#x27;s now a FederatedDataset</span></span><br><span class="line">    batch_size=args.batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))</span><br><span class="line">                   ])),</span><br><span class="line">    batch_size=args.test_batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">50</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">4</span>*<span class="number">4</span>*<span class="number">50</span>, <span class="number">500</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">500</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = F.relu(self.conv2(x))</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">4</span>*<span class="number">4</span>*<span class="number">50</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args, models, device, federated_train_loader, epoch</span>):</span><br><span class="line">    <span class="keyword">for</span> client_id <span class="keyword">in</span> federated_train_loader.workers:</span><br><span class="line">        <span class="comment"># 将全局模型发给 当前client</span></span><br><span class="line">        model = models[<span class="string">&#x27;global_model&#x27;</span>].copy().send(workers[client_id])</span><br><span class="line">        model.train()</span><br><span class="line">        optimizer =optim.SGD(params=model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line">        <span class="comment"># 构造 当前client的数据集</span></span><br><span class="line">        one_client_train_loader = federated_train_loader.federated_dataset[client_id]</span><br><span class="line">        dataset = sy.BaseDataset(one_client_train_loader.data, one_client_train_loader.targets)</span><br><span class="line">        dataset = sy.FederatedDataset([dataset])</span><br><span class="line">        one_client_train_loader = sy.FederatedDataLoader(dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">False</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 当前client开始本地训练</span></span><br><span class="line">        <span class="keyword">for</span> local_epoch <span class="keyword">in</span> <span class="built_in">range</span>(local_epochs):</span><br><span class="line">            loss_per_local_epoch = []</span><br><span class="line">            <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(one_client_train_loader):  <span class="comment"># &lt;-- now it is a distributed dataset</span></span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                data, target = data.to(device), target.to(device)</span><br><span class="line">                output = model(data)</span><br><span class="line">                loss = F.nll_loss(output, target)</span><br><span class="line">                loss.backward()</span><br><span class="line">                optimizer.step()</span><br><span class="line">                loss = loss.get()</span><br><span class="line">                loss_per_local_epoch.append(loss.item())</span><br><span class="line">            <span class="comment"># 每个client 每个，本地epoch 打印一次</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;client: &#123;&#125; , Train Global_Epoch: &#123;&#125;, Local_Epoch: &#123;&#125;, avg_loss: &#123;&#125; &#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                client_id, epoch, local_epoch,np.mean(loss_per_local_epoch)))</span><br><span class="line">        models[client_id] = model.copy().get()</span><br><span class="line">    <span class="keyword">return</span> models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fedAvg</span>(<span class="params">arg,models,federated_train_loader</span>):</span><br><span class="line">    global_model = models[<span class="string">&#x27;global_model&#x27;</span>]</span><br><span class="line">    global_state_dict = global_model.state_dict()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> global_state_dict.keys():</span><br><span class="line">        one_layer_weight_or_bias = global_state_dict[key].zero_()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> client_id <span class="keyword">in</span> federated_train_loader.workers:</span><br><span class="line">            model = models[client_id]</span><br><span class="line">            one_layer_weight_or_bias += model.state_dict()[key].data.clone()</span><br><span class="line"></span><br><span class="line">        global_state_dict[key] = one_layer_weight_or_bias / <span class="built_in">len</span>(federated_train_loader.workers)</span><br><span class="line"></span><br><span class="line">    global_model.load_state_dict(global_state_dict)</span><br><span class="line">    models[<span class="string">&#x27;global_model&#x27;</span>] = global_model</span><br><span class="line">    <span class="keyword">return</span> models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">args, models, device, test_loader</span>):</span><br><span class="line">    model = models[<span class="string">&#x27;global_model&#x27;</span>]</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            output = model(data)</span><br><span class="line">            test_loss += F.nll_loss(output, target, reduction=<span class="string">&#x27;sum&#x27;</span>).item() <span class="comment"># sum up batch loss</span></span><br><span class="line">            pred = output.argmax(<span class="number">1</span>, keepdim=<span class="literal">True</span>) <span class="comment"># get the index of the max log-probability</span></span><br><span class="line">            correct += pred.eq(target.view_as(pred)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">global_model = Net().to(device)</span><br><span class="line">global_optimizer = optim.SGD(global_model.parameters(), lr=args.lr) <span class="comment"># TODO momentum is not supported at the moment</span></span><br><span class="line">bobs_model = global_model.copy().send(bob)</span><br><span class="line">alices_model = global_model.copy().send(alice)</span><br><span class="line">models = &#123;&#125;</span><br><span class="line">models[<span class="string">&#x27;bob&#x27;</span>] = bobs_model</span><br><span class="line">models[<span class="string">&#x27;alice&#x27;</span>] = alices_model</span><br><span class="line">models[<span class="string">&#x27;global_model&#x27;</span>] = global_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.epochs + <span class="number">1</span>):</span><br><span class="line">    models = train(args, models, device, federated_train_loader, epoch)</span><br><span class="line">    models = fedAvg(args,models,federated_train_loader)</span><br><span class="line">    test(args, models, device, test_loader)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (args.save_model):</span><br><span class="line">    torch.save(global_model.state_dict(), <span class="string">&quot;mnist_cnn.pt&quot;</span>)</span><br></pre></td></tr></table></figure>



<h2 id="7-使用安全多方计算-SMPC-加密算法-实现-FedAVG"><a href="#7-使用安全多方计算-SMPC-加密算法-实现-FedAVG" class="headerlink" title="7. 使用安全多方计算 (SMPC)加密算法 实现 FedAVG"></a>7. 使用安全多方计算 (SMPC)加密算法 实现 FedAVG</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset, DataLoader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Parser</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Parameters for training&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.epochs = <span class="number">10</span></span><br><span class="line">        self.lr = <span class="number">0.001</span></span><br><span class="line">        self.test_batch_size = <span class="number">8</span></span><br><span class="line">        self.batch_size = <span class="number">8</span></span><br><span class="line">        self.log_interval = <span class="number">10</span></span><br><span class="line">        self.seed = <span class="number">1</span></span><br><span class="line">        self.download_boston_housing = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">args = Parser()</span><br><span class="line"></span><br><span class="line">torch.manual_seed(args.seed)</span><br><span class="line">kwargs = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载数据集</span></span><br><span class="line"><span class="keyword">if</span> args.download_boston_housing:</span><br><span class="line">    <span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">    boston_housing = tf.keras.datasets.boston_housing</span><br><span class="line">    pickle_data = boston_housing.load_data()</span><br><span class="line">    pickle.dump(pickle_data, <span class="built_in">open</span>(<span class="string">&#x27;./data/BostonHousing/boston_housing.pickle&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./data/BostonHousing/boston_housing.pickle&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    ((X, y), (X_test, y_test)) = pickle.load(f)</span><br><span class="line"></span><br><span class="line">X = torch.from_numpy(X).<span class="built_in">float</span>()</span><br><span class="line">y = torch.from_numpy(y).<span class="built_in">float</span>()</span><br><span class="line">X_test = torch.from_numpy(X_test).<span class="built_in">float</span>()</span><br><span class="line">y_test = torch.from_numpy(y_test).<span class="built_in">float</span>()</span><br><span class="line"><span class="comment"># preprocessing</span></span><br><span class="line">mean = X.mean(<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">dev = X.std(<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">mean[:, <span class="number">3</span>] = <span class="number">0.</span> <span class="comment"># the feature at column 3 is binary,</span></span><br><span class="line">dev[:, <span class="number">3</span>] = <span class="number">1.</span>  <span class="comment"># so we don&#x27;t standardize it</span></span><br><span class="line">X = (X - mean) / dev</span><br><span class="line">X_test = (X_test - mean) / dev</span><br><span class="line">train = TensorDataset(X, y)</span><br><span class="line">test = TensorDataset(X_test, y_test)</span><br><span class="line">train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line">test_loader = DataLoader(test, batch_size=args.test_batch_size, shuffle=<span class="literal">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">13</span>, <span class="number">32</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">32</span>, <span class="number">24</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">24</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">13</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bobs_model = Net()</span><br><span class="line">alices_model = Net()</span><br><span class="line"></span><br><span class="line">bobs_optimizer = optim.SGD(bobs_model.parameters(), lr=args.lr)</span><br><span class="line">alices_optimizer = optim.SGD(alices_model.parameters(), lr=args.lr)</span><br><span class="line"></span><br><span class="line">models = [bobs_model, alices_model]</span><br><span class="line">params = [<span class="built_in">list</span>(bobs_model.parameters()), <span class="built_in">list</span>(alices_model.parameters())]</span><br><span class="line">optimizers = [bobs_optimizer, alices_optimizer]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> syft <span class="keyword">as</span> sy</span><br><span class="line"></span><br><span class="line">hook = sy.TorchHook(torch)</span><br><span class="line">bob = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;bob&quot;</span>)</span><br><span class="line">alice = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;alice&quot;</span>)</span><br><span class="line">james = sy.VirtualWorker(hook, <span class="built_in">id</span>=<span class="string">&quot;james&quot;</span>)</span><br><span class="line"></span><br><span class="line">compute_nodes = [bob, alice]</span><br><span class="line"></span><br><span class="line">remote_dataset = (<span class="built_in">list</span>(),<span class="built_in">list</span>())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将训练集分发到远程节点bob，alice</span></span><br><span class="line"><span class="keyword">for</span> batch_idx, (data,target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">    worker_i_index = batch_idx % <span class="built_in">len</span>(compute_nodes)</span><br><span class="line">    worker_i = compute_nodes[worker_i_index]</span><br><span class="line">    data = data.send(worker_i)</span><br><span class="line">    target = target.send(worker_i)</span><br><span class="line">    remote_dataset[worker_i_index].append((data, target))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 单个客户端上， 使用 单个 batch_size 大小的数据集进行一次训练</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">data, target, model, optimizer</span>):</span><br><span class="line">    model.send(data.location)</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    pred = model(data)</span><br><span class="line">    loss = F.mse_loss(pred.view(-<span class="number">1</span>), target)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 完整训练</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    <span class="comment"># 对单个 batch_size 大小的数据集进行一次训练</span></span><br><span class="line">    <span class="keyword">for</span> data_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(remote_dataset[<span class="number">0</span>])-<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># update remote models</span></span><br><span class="line">        <span class="comment"># 对每个远程节点，获取 单个 batch_size 大小的数据集，进行一次训练</span></span><br><span class="line">        <span class="keyword">for</span> remote_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(compute_nodes)):</span><br><span class="line">            data, target = remote_dataset[remote_index][data_index]</span><br><span class="line">            models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># encrypted aggregation</span></span><br><span class="line">        new_params = <span class="built_in">list</span>()</span><br><span class="line">        <span class="comment"># 对于每个参数，进行加密聚合</span></span><br><span class="line">        <span class="keyword">for</span> param_i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(params[<span class="number">0</span>])):</span><br><span class="line">            spdz_params = <span class="built_in">list</span>()</span><br><span class="line">            <span class="comment"># 聚合 每个节点上，对应 param_key 里面的参数值</span></span><br><span class="line">            <span class="keyword">for</span> remote_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(compute_nodes)):</span><br><span class="line">                <span class="comment"># 对每个节点上的参数，进行加密</span></span><br><span class="line">                spdz_params.append(params[remote_index][param_i].fix_precision().share(bob, alice, crypto_provider=james).get())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 此时 spdz_params 是一个列表，列表里面有两个元素，每个元素是一个加密的参数值</span></span><br><span class="line">            new_param = (spdz_params[<span class="number">0</span>] + spdz_params[<span class="number">1</span>]).get().float_precision()/<span class="number">2</span></span><br><span class="line">            new_params.append(new_param)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># cleanup</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> model <span class="keyword">in</span> params:</span><br><span class="line">                <span class="keyword">for</span> param <span class="keyword">in</span> model:</span><br><span class="line">                    param *= <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">                model.get()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将聚合好的参数，赋值给每个节点的模型</span></span><br><span class="line">            <span class="keyword">for</span> remote_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(compute_nodes)):</span><br><span class="line">                <span class="keyword">for</span> param_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(params[remote_index])):</span><br><span class="line">                    params[remote_index][param_index].set_(new_params[param_index])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    models[<span class="number">0</span>].<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">        output = models[<span class="number">0</span>](data)</span><br><span class="line">        test_loss += F.mse_loss(output.view(-<span class="number">1</span>), target, reduction=<span class="string">&#x27;sum&#x27;</span>).item()  <span class="comment"># sum up batch loss</span></span><br><span class="line">        pred = output.data.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>]  <span class="comment"># get the index of the max log-probability</span></span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test set: Average loss: &#123;:.4f&#125;\n&#x27;</span>.<span class="built_in">format</span>(test_loss))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">t = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">    train(epoch)</span><br><span class="line">    test()</span><br><span class="line"></span><br><span class="line">total_time = time.time() - t</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Total&#x27;</span>, <span class="built_in">round</span>(total_time, <span class="number">2</span>), <span class="string">&#x27;s&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test()</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%BF%83%E5%BE%97/" rel="tag"># 心得</a>
              <a href="/tags/pysyft/" rel="tag"># pysyft</a>
              <a href="/tags/%E5%AE%9E%E6%88%98/" rel="tag"># 实战</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/12/09/idea-stream-debug/" rel="prev" title="idea调试java stream插件">
      <i class="fa fa-chevron-left"></i> idea调试java stream插件
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/01/05/excludes-rubbish-websites/" rel="next" title="排除垃圾网站">
      排除垃圾网站 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="nav-number">1.</span> <span class="nav-text">1.环境搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-python-3-7"><span class="nav-number">1.1.</span> <span class="nav-text">(1)python-3.7</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-pytorch-1-4-0"><span class="nav-number">1.2.</span> <span class="nav-text">(2) pytorch-1.4.0</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-syft-0-2-9"><span class="nav-number">1.3.</span> <span class="nav-text">(3) syft-0.2.9</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-protobuf-3-20-3"><span class="nav-number">1.4.</span> <span class="nav-text">(4)   protobuf-3.20.3</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-demo-%E9%AA%8C%E8%AF%81"><span class="nav-number">2.</span> <span class="nav-text">2. demo 验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AE%80%E5%8D%95%E6%A1%88%E4%BE%8B"><span class="nav-number">3.</span> <span class="nav-text">3. 联邦学习简单案例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-FedAvg"><span class="nav-number">4.</span> <span class="nav-text">4. FedAvg</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E4%BD%BF%E7%94%A8fedsgd%E8%AE%AD%E7%BB%83-CNN-%E7%BD%91%E7%BB%9C"><span class="nav-number">5.</span> <span class="nav-text">5.使用fedsgd训练  CNN 网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8E%E5%8D%95%E6%9C%BA%E7%89%88%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">5.1.</span> <span class="nav-text">与单机版训练的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="nav-number">5.2.</span> <span class="nav-text">完整代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E4%BD%BF%E7%94%A8fedavg-%E8%AE%AD%E7%BB%83CNN%E7%BD%91%E7%BB%9C"><span class="nav-number">6.</span> <span class="nav-text">6.使用fedavg 训练CNN网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-%E4%BD%BF%E7%94%A8%E5%AE%89%E5%85%A8%E5%A4%9A%E6%96%B9%E8%AE%A1%E7%AE%97-SMPC-%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95-%E5%AE%9E%E7%8E%B0-FedAVG"><span class="nav-number">7.</span> <span class="nav-text">7. 使用安全多方计算 (SMPC)加密算法 实现 FedAVG</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Promise Chan"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">Promise Chan</p>
  <div class="site-description" itemprop="description">Coding & upgrading</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/promiseChan" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;promiseChan" rel="noopener" target="_blank"><i class="fa fa-fw fa-fab fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>


      
           <div>
              <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="210" height="110" src="//music.163.com/outchain/player?type=2&id=27515286&auto=1&height=32"></iframe>
           </div>
         
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Promise Chan</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div><a href="https://icp.gov.moe/?keyword=20180708" rel="external nofollow noreferrer" target="_blank" data-pjax-state="" style="
    border-bottom-width: 0px;
">萌 ICP 备 20180708 号</a>
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/10/2022 22:00:00");//此处修改你的建站时间，注意格式
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "小站在混沌中存活了 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
